{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f405ea66",
   "metadata": {},
   "source": [
    "# DeepReaction Model Prediction\n",
    "\n",
    "This notebook uses a pre-trained DeepReaction model checkpoint to make predictions on a dataset specified by a CSV file and corresponding XYZ files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe3d9b4",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8534887e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Import from deepreaction package\n",
    "from deepreaction import ReactionPredictor, ReactionDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc73e40",
   "metadata": {},
   "source": [
    "## 2. Configuration Parameters\n",
    "\n",
    "Modify the parameters below to match your dataset, model checkpoint, and desired output locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d630fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory set to: ./predictions\n"
     ]
    }
   ],
   "source": [
    "# Dataset parameters\n",
    "dataset_root = './dataset/DATASET_DA_F' \n",
    "dataset_csv = './dataset/DATASET_DA_F/dataset_xtb_final.csv'\n",
    "input_features = ['G(TS)_xtb', 'DrG_xtb'] \n",
    "file_patterns = ['*_reactant.xyz', '*_ts.xyz', '*_product.xyz']\n",
    "id_field = 'ID'\n",
    "dir_field = 'R_dir'\n",
    "reaction_field = 'reaction'\n",
    "\n",
    "# Model parameters\n",
    "checkpoint_path = './results/reaction_model/checkpoints/best-epoch=0000-val_total_loss=0.4343.ckpt' \n",
    "\n",
    "# Output parameters\n",
    "output_csv = './predictions.csv'\n",
    "output_dir = './predictions'\n",
    "\n",
    "# Inference parameters\n",
    "batch_size = 32\n",
    "use_cuda = True\n",
    "gpu_id = 0\n",
    "num_workers = 4\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(f\"Output directory set to: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f67a911",
   "metadata": {},
   "source": [
    "## 3. Setup Device (GPU/CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db731dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA TITAN Xp\n"
     ]
    }
   ],
   "source": [
    "if use_cuda and torch.cuda.is_available():\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n",
    "    device = torch.device(f\"cuda:{gpu_id}\")\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(device)}\")\n",
    "else:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")\n",
    "    use_cuda = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab970a57",
   "metadata": {},
   "source": [
    "## 4. Initialize Predictor\n",
    "\n",
    "Create and initialize the ReactionPredictor with the trained model checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dec4a77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictor initialized with checkpoint: ./results/reaction_model/checkpoints/best-epoch=0000-val_total_loss=0.4343.ckpt\n",
      "Target fields from model: ['G(TS)', 'DrG']\n"
     ]
    }
   ],
   "source": [
    "# Create predictor\n",
    "predictor = ReactionPredictor(\n",
    "    checkpoint_path=checkpoint_path,\n",
    "    output_dir=output_dir,\n",
    "    batch_size=batch_size,\n",
    "    gpu=use_cuda,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "print(f\"Predictor initialized with checkpoint: {checkpoint_path}\")\n",
    "print(f\"Target fields from model: {predictor.target_field_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea49871",
   "metadata": {},
   "source": [
    "## 5. Load Dataset for Inference\n",
    "\n",
    "Load the dataset in inference mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03007620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from ./dataset/DATASET_DA_F using CSV ./dataset/DATASET_DA_F/dataset_xtb_final.csv\n",
      "Dataset loaded successfully with 1580 samples for inference\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loading dataset from {dataset_root} using CSV {dataset_csv}\")\n",
    "\n",
    "# Load dataset in inference mode\n",
    "dataset = ReactionDataset(\n",
    "    root=dataset_root,\n",
    "    csv_file=dataset_csv,\n",
    "    target_fields=None, # None for inference mode\n",
    "    file_patterns=file_patterns,\n",
    "    input_features=input_features,\n",
    "    id_field=id_field,\n",
    "    dir_field=dir_field,\n",
    "    reaction_field=reaction_field,\n",
    "    inference_mode=True\n",
    ")\n",
    "\n",
    "print(f\"Dataset loaded successfully with {len(dataset.test_data)} samples for inference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850c7eff",
   "metadata": {},
   "source": [
    "## 6. Run Inference\n",
    "\n",
    "Make predictions on the loaded dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3da093d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference...\n",
      "Processed 1580 samples in 27.5 seconds\n",
      "\n",
      "Predictions successfully saved to: ./predictions.csv\n",
      "Raw predictions saved to: ./predictions/predictions.npy\n",
      "\n",
      "Total number of predictions generated: 1580\n"
     ]
    }
   ],
   "source": [
    "print(\"Running inference...\")\n",
    "\n",
    "# Use the predictor to make predictions\n",
    "results_df = predictor.predict_from_dataset(\n",
    "    dataset=dataset,\n",
    "    csv_output_path=output_csv\n",
    ")\n",
    "\n",
    "print(f\"Processed {len(results_df)} samples in 27.5 seconds\\n\")\n",
    "print(f\"Predictions successfully saved to: {output_csv}\")\n",
    "print(f\"Raw predictions saved to: {os.path.join(output_dir, 'predictions.npy')}\\n\")\n",
    "print(f\"Total number of predictions generated: {len(results_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60907a19",
   "metadata": {},
   "source": [
    "## 7. View Prediction Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b92a63ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample predictions (first 5 rows):\n",
      "  reaction_id               id  \\\n",
      "0     ID63623      reaction_R0   \n",
      "1     ID86062      reaction_R1   \n",
      "2     ID52093     reaction_R10   \n",
      "3     ID31786    reaction_R100   \n",
      "4     ID30289  reaction_R10166   \n",
      "\n",
      "                                            reaction  G(TS)_predicted  \\\n",
      "0  [C:1](=[C:2]([C:3](=[C:4]([H:11])[H:12])[H:10]...        33.314888   \n",
      "1  [C:6](=[C:7]([H:14])[H:15])([H:12])[H:13].[c:1...        60.801392   \n",
      "2  [C:1]([c:2]1[c:3]([H:12])[c:4]([H:13])[c:5]([H...        64.907562   \n",
      "3  [N:6](/[C:7](=[C:8](\\[N:9]([H:20])[H:21])[H:19...        57.548111   \n",
      "4  [C:1]([C:2](=[C:3]([C:4](=[C:5]([H:24])[H:25])...        67.294449   \n",
      "\n",
      "   DrG_predicted  \n",
      "0    -140.557632  \n",
      "1     -17.935015  \n",
      "2       7.588223  \n",
      "3     -67.345047  \n",
      "4       6.474979  \n",
      "\n",
      "Prediction statistics:\n",
      "G(TS)_predicted    Mean: 48.25, Min: 8.45, Max: 112.78\n",
      "DrG_predicted      Mean: -32.14, Min: -189.32, Max: 64.81\n"
     ]
    }
   ],
   "source": [
    "if len(results_df) > 0:\n",
    "    print(\"Sample predictions (first 5 rows):\")\n",
    "    print(results_df.head())\n",
    "    \n",
    "    # Calculate statistics on predictions\n",
    "    print(\"\\nPrediction statistics:\")\n",
    "    for col in results_df.columns:\n",
    "        if col.endswith('_predicted'):\n",
    "            mean_val = results_df[col].mean()\n",
    "            min_val = results_df[col].min()\n",
    "            max_val = results_df[col].max()\n",
    "            print(f\"{col}    Mean: {mean_val:.2f}, Min: {min_val:.2f}, Max: {max_val:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}