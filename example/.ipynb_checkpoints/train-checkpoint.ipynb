{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Reaction Model Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add current directory to path for local imports\n",
    "sys.path.insert(0, str(Path('.').absolute()))\n",
    "\n",
    "from deepreaction import Config, ReactionDataset, ReactionTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration Parameters\n",
    "\n",
    "Define all hyperparameters and settings for the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration parameters\n",
    "params = {\n",
    "    # Dataset configuration\n",
    "    'dataset': 'XTB',\n",
    "    'readout': 'mean',\n",
    "    'dataset_root': './dataset/DATASET_DA_F',\n",
    "    'dataset_csv': './dataset/DATASET_DA_F/dataset_xtb_final.csv',\n",
    "    'train_ratio': 0.8,\n",
    "    'val_ratio': 0.1,\n",
    "    'test_ratio': 0.1,\n",
    "    'target_fields': ['DG_act', 'DrG'],\n",
    "    'target_weights': [1.0, 1.0],\n",
    "    'input_features': ['DG_act_xtb', 'DrG_xtb'],\n",
    "    'file_patterns': ['*_reactant.xyz', '*_ts.xyz', '*_product.xyz'],\n",
    "    'file_dir_pattern': 'reaction_*',\n",
    "    'id_field': 'ID',\n",
    "    'dir_field': 'R_dir',\n",
    "    'reaction_field': 'smiles',\n",
    "    \n",
    "    # Cross-validation settings\n",
    "    'cv_folds': 0,\n",
    "    'use_scaler': True,\n",
    "    'val_csv': None,\n",
    "    'test_csv': None,\n",
    "    'cv_test_fold': -1,\n",
    "    'cv_stratify': False,\n",
    "    'cv_grouped': True,\n",
    "    'file_suffixes': ['_reactant.xyz', '_ts.xyz', '_product.xyz'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model architecture parameters\n",
    "model_params = {\n",
    "    'model_type': 'dimenet++',\n",
    "    'node_dim': 128,\n",
    "    'dropout': 0.1,\n",
    "    'prediction_hidden_layers': 3,\n",
    "    'prediction_hidden_dim': 512,\n",
    "    'use_layer_norm': False,\n",
    "    'activation': 'silu',\n",
    "    'use_xtb_features': True,\n",
    "    'max_num_atoms': 100,\n",
    "    \n",
    "    # DimeNet++ specific parameters\n",
    "    'hidden_channels': 128,\n",
    "    'num_blocks': 5,\n",
    "    'int_emb_size': 64,\n",
    "    'basis_emb_size': 8,\n",
    "    'out_emb_channels': 256,\n",
    "    'num_spherical': 7,\n",
    "    'num_radial': 6,\n",
    "    'cutoff': 5.0,\n",
    "    'envelope_exponent': 5,\n",
    "    'num_before_skip': 1,\n",
    "    'num_after_skip': 2,\n",
    "    'num_output_layers': 3,\n",
    "    'max_num_neighbors': 32,\n",
    "    \n",
    "    # Readout layer parameters\n",
    "    'readout_hidden_dim': 128,\n",
    "    'readout_num_heads': 4,\n",
    "    'readout_num_sabs': 2,\n",
    "}\n",
    "\n",
    "# Add model parameters to main params\n",
    "params.update(model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "training_params = {\n",
    "    'batch_size': 16,\n",
    "    'eval_batch_size': 32,\n",
    "    'lr': 0.0005,\n",
    "    'finetune_lr': None,\n",
    "    'max_epochs': 4,\n",
    "    'min_epochs': 0,\n",
    "    'early_stopping_patience': 40,\n",
    "    'early_stopping_min_delta': 0.0001,\n",
    "    'optimizer': 'adamw',\n",
    "    'scheduler': 'warmup_cosine',\n",
    "    'warmup_epochs': 10,\n",
    "    'min_lr': 1e-7,\n",
    "    'weight_decay': 0.0001,\n",
    "    'random_seed': 42234,\n",
    "    'loss_function': 'mse',\n",
    "    'gradient_clip_val': 0.0,\n",
    "    'gradient_accumulation_steps': 1,\n",
    "    'precision': '32',\n",
    "}\n",
    "\n",
    "# Add training parameters to main params\n",
    "params.update(training_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration parameters loaded successfully!\n",
      "Total parameters: 82\n"
     ]
    }
   ],
   "source": [
    "# Output and system configuration\n",
    "system_params = {\n",
    "    'out_dir': './results/reaction_model',\n",
    "    'save_best_model': True,\n",
    "    'save_last_model': False,\n",
    "    'save_predictions': True,\n",
    "    'save_interval': 0,\n",
    "    'checkpoint_path': None,\n",
    "    'mode': 'train',\n",
    "    'freeze_base_model': False,\n",
    "    \n",
    "    # Hardware configuration\n",
    "    'cuda': True,\n",
    "    'gpu_id': 0,\n",
    "    'num_workers': 4,\n",
    "    'strategy': 'auto',\n",
    "    'num_nodes': 1,\n",
    "    'devices': 1,\n",
    "    'log_level': 'info',\n",
    "    'log_to_file': False,\n",
    "}\n",
    "\n",
    "# Add system parameters to main params\n",
    "params.update(system_params)\n",
    "\n",
    "print(\"Configuration parameters loaded successfully!\")\n",
    "print(f\"Total parameters: {len(params)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Device Setup\n",
    "\n",
    "Configure GPU/CPU usage and check available hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA GeForce RTX 3080 Ti\n",
      "GPU Memory: 12.6 GB\n",
      "PyTorch version: 2.3.0+cu121\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "# Setup device (GPU/CPU)\n",
    "if params['cuda'] and torch.cuda.is_available():\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(params['gpu_id'])\n",
    "    device = torch.device(f\"cuda:{params['gpu_id']}\")\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(device)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(device).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")\n",
    "    params['cuda'] = False\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Configuration Object\n",
    "\n",
    "Initialize the configuration object from parameters and display key settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating configuration...\n",
      "Dataset: XTB\n",
      "Model: dimenet++\n",
      "Target fields: ['DG_act', 'DrG']\n",
      "Input features: ['DG_act_xtb', 'DrG_xtb']\n",
      "Batch size: 16\n",
      "Learning rate: 0.0005\n",
      "Max epochs: 4\n",
      "Output directory: ./results/reaction_model\n",
      "\n",
      "Configuration created successfully!\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating configuration...\")\n",
    "config = Config.from_params(params)\n",
    "\n",
    "# Display key configuration details\n",
    "if params['log_level'] == 'debug':\n",
    "    config.print_config()\n",
    "else:\n",
    "    print(f\"Dataset: {config.dataset.dataset}\")\n",
    "    print(f\"Model: {config.model.model_type}\")\n",
    "    print(f\"Target fields: {config.dataset.target_fields}\")\n",
    "    print(f\"Input features: {config.dataset.input_features}\")\n",
    "    print(f\"Batch size: {config.training.batch_size}\")\n",
    "    print(f\"Learning rate: {config.training.lr}\")\n",
    "    print(f\"Max epochs: {config.training.max_epochs}\")\n",
    "    print(f\"Output directory: {config.training.out_dir}\")\n",
    "\n",
    "print(\"\\nConfiguration created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load Dataset\n",
    "\n",
    "Load and prepare the reaction dataset for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-23 13:31:26,344 - deepreaction - INFO - Loading reaction dataset...\n",
      "2025-05-23 13:31:26,346 - deepreaction - INFO - Loading single dataset with automatic train/val/test split\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Target fields changed from None to ['DG_act', 'DrG']\n",
      "Removing old processed file: dataset/DATASET_DA_F/processed/data_f74edeff.pt\n",
      "Using target fields: ['DG_act', 'DrG']\n",
      "Using input features: ['DG_act_xtb', 'DrG_xtb']\n",
      "Using file suffixes: reactant='_reactant.xyz', ts='_ts.xyz', product='_product.xyz'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing reactions:  76%|███████▌  | 1202/1582 [00:00<00:00, 1997.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Folder dataset/DATASET_DA_F/reaction_R6866 does not exist, skipping reaction_id ID79335\n",
      "Warning: Folder dataset/DATASET_DA_F/reaction_R6867 does not exist, skipping reaction_id ID79335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing reactions: 100%|██████████| 1582/1582 [00:00<00:00, 1986.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved metadata to dataset/DATASET_DA_F/processed/metadata.json\n",
      "Processed 1580 reactions, saved to dataset/DATASET_DA_F/processed/data_f74edeff.pt\n",
      "Dataset split: train 1269, validation 162, test 149 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-23 13:31:27,793 - deepreaction - INFO - Data splits: train=1269, val=162, test=149\n",
      "2025-05-23 13:31:27,808 - deepreaction - INFO - Scaler 0: mean=37.6035, std=8.8419\n",
      "2025-05-23 13:31:27,822 - deepreaction - INFO - Scaler 1: mean=-4.6943, std=16.5769\n",
      "2025-05-23 13:31:27,822 - deepreaction - INFO - Trained 2 scalers\n",
      "2025-05-23 13:31:28,994 - deepreaction - INFO - Loaded train: 1269, val: 162, test: 149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: train=1269, val=162, test=149\n",
      "Dataset loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading dataset...\")\n",
    "dataset = ReactionDataset(config=config)\n",
    "\n",
    "# Check if cross-validation is enabled\n",
    "if config.reaction.cv_folds > 0:\n",
    "    print(f\"Cross-validation enabled with {dataset.get_num_folds()} folds.\")\n",
    "else:\n",
    "    train_data, val_data, test_data, scalers = dataset.get_data_splits()\n",
    "    print(f\"Dataset loaded: train={len(train_data)}, val={len(val_data)}, test={len(test_data)}\")\n",
    "\n",
    "print(\"Dataset loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Initialize Trainer\n",
    "\n",
    "Set up the training environment and model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-23 13:31:29,000 - deepreaction - INFO - Using GPU: NVIDIA GeForce RTX 3080 Ti\n",
      "2025-05-23 13:31:29,002 - deepreaction - INFO - Validating configuration...\n",
      "2025-05-23 13:31:29,003 - deepreaction - INFO - Configuration validation completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing trainer...\n",
      "Trainer initialized successfully\n",
      "Starting training with 4 epochs\n"
     ]
    }
   ],
   "source": [
    "print(\"Initializing trainer...\")\n",
    "trainer = ReactionTrainer(config=config)\n",
    "\n",
    "print(\"Trainer initialized successfully\")\n",
    "print(f\"Starting training with {config.training.max_epochs} epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train the Model\n",
    "\n",
    "Execute the training process and monitor progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42234\n",
      "2025-05-23 13:31:29,011 - deepreaction - INFO - Set random seed to 42234\n",
      "2025-05-23 13:31:29,016 - deepreaction - INFO - Configuration saved to ./results/reaction_model/config.json\n",
      "2025-05-23 13:31:29,016 - deepreaction - INFO - Creating dataloader: batch_size=16, num_workers=4, eval_mode=False\n",
      "2025-05-23 13:31:29,017 - deepreaction - INFO - Creating dataloader: batch_size=32, num_workers=2, eval_mode=True\n",
      "2025-05-23 13:31:29,017 - deepreaction - INFO - Created dataloaders: train=80, val=6 batches\n",
      "2025-05-23 13:31:29,018 - deepreaction - INFO - Creating model with 2 targets and 2 input features\n",
      "2025-05-23 13:31:29,018 - deepreaction - INFO - Model configuration:\n",
      "2025-05-23 13:31:29,019 - deepreaction - INFO -   model_type: dimenet++\n",
      "2025-05-23 13:31:29,019 - deepreaction - INFO -   readout: mean\n",
      "2025-05-23 13:31:29,020 - deepreaction - INFO -   batch_size: 16\n",
      "2025-05-23 13:31:29,020 - deepreaction - INFO -   lr: 0.0005\n",
      "2025-05-23 13:31:29,020 - deepreaction - INFO -   max_num_atoms_in_mol: 100\n",
      "2025-05-23 13:31:29,021 - deepreaction - INFO -   use_layer_norm: False\n",
      "2025-05-23 13:31:29,021 - deepreaction - INFO -   node_latent_dim: 128\n",
      "2025-05-23 13:31:29,022 - deepreaction - INFO -   edge_latent_dim: 128\n",
      "2025-05-23 13:31:29,022 - deepreaction - INFO -   dropout: 0.1\n",
      "2025-05-23 13:31:29,022 - deepreaction - INFO -   optimizer: adamw\n",
      "2025-05-23 13:31:29,023 - deepreaction - INFO -   weight_decay: 0.0001\n",
      "2025-05-23 13:31:29,023 - deepreaction - INFO -   scheduler: warmup_cosine\n",
      "2025-05-23 13:31:29,024 - deepreaction - INFO -   scheduler_patience: 10\n",
      "2025-05-23 13:31:29,024 - deepreaction - INFO -   scheduler_factor: 0.5\n",
      "2025-05-23 13:31:29,025 - deepreaction - INFO -   warmup_epochs: 10\n",
      "2025-05-23 13:31:29,025 - deepreaction - INFO -   min_lr: 1e-07\n",
      "2025-05-23 13:31:29,026 - deepreaction - INFO -   loss_function: mse\n",
      "2025-05-23 13:31:29,026 - deepreaction - INFO -   target_weights: [1.0, 1.0]\n",
      "2025-05-23 13:31:29,026 - deepreaction - INFO -   uncertainty_method: None\n",
      "2025-05-23 13:31:29,027 - deepreaction - INFO -   gradient_clip_val: 0.0\n",
      "2025-05-23 13:31:29,027 - deepreaction - INFO -   use_xtb_features: True\n",
      "2025-05-23 13:31:29,027 - deepreaction - INFO -   num_xtb_features: 2\n",
      "2025-05-23 13:31:29,028 - deepreaction - INFO -   prediction_hidden_layers: 3\n",
      "2025-05-23 13:31:29,028 - deepreaction - INFO -   prediction_hidden_dim: 512\n",
      "2025-05-23 13:31:29,028 - deepreaction - INFO -   target_field_names: ['DG_act', 'DrG']\n",
      "2025-05-23 13:31:29,029 - deepreaction - INFO - Using 2 scalers\n",
      "2025-05-23 13:31:29,351 - deepreaction - INFO - Added best model checkpoint callback\n",
      "2025-05-23 13:31:29,352 - deepreaction - INFO - Added early stopping callback (patience: 40)\n",
      "2025-05-23 13:31:29,354 - deepreaction - INFO - Setup loggers in ./results/reaction_model\n",
      "2025-05-23 13:31:29,354 - deepreaction - INFO - Trainer configuration:\n",
      "2025-05-23 13:31:29,355 - deepreaction - INFO -   max_epochs: 4\n",
      "2025-05-23 13:31:29,355 - deepreaction - INFO -   min_epochs: 0\n",
      "2025-05-23 13:31:29,356 - deepreaction - INFO -   log_every_n_steps: 10\n",
      "2025-05-23 13:31:29,356 - deepreaction - INFO -   deterministic: True\n",
      "2025-05-23 13:31:29,357 - deepreaction - INFO -   accelerator: gpu\n",
      "2025-05-23 13:31:29,357 - deepreaction - INFO -   num_sanity_val_steps: 2\n",
      "2025-05-23 13:31:29,358 - deepreaction - INFO -   gradient_clip_val: None\n",
      "2025-05-23 13:31:29,358 - deepreaction - INFO -   accumulate_grad_batches: 1\n",
      "2025-05-23 13:31:29,359 - deepreaction - INFO -   precision: 32\n",
      "2025-05-23 13:31:29,359 - deepreaction - INFO -   strategy: auto\n",
      "2025-05-23 13:31:29,360 - deepreaction - INFO -   num_nodes: 1\n",
      "2025-05-23 13:31:29,360 - deepreaction - INFO -   devices: 1\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025-05-23 13:31:29,381 - deepreaction - INFO - Starting training for 4 epochs\n",
      "2025-05-23 13:31:29,381 - deepreaction - INFO - Training dataset size: 1269\n",
      "2025-05-23 13:31:29,381 - deepreaction - INFO - Validation dataset size: 162\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type                      | Params | Mode \n",
      "---------------------------------------------------------------------\n",
      "0 | model          | MoleculePredictionModel   | 3.5 M  | train\n",
      "1 | net            | DimeNetPlusPlus           | 2.2 M  | train\n",
      "2 | readout_module | MeanReadout               | 0      | train\n",
      "3 | regr_or_cls_nn | MultiTargetPredictionHead | 1.2 M  | train\n",
      "---------------------------------------------------------------------\n",
      "3.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.5 M     Total params\n",
      "13.866    Total estimated model params size (MB)\n",
      "193       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d729442b9cc1433ea1bb281b79897803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_total_loss improved. New best score: 0.492\n",
      "Epoch 0, global step 80: 'val_total_loss' reached 0.49227 (best 0.49227), saving model to '/root/autodl-tmp/new/original8/results/reaction_model/checkpoints/best-epoch=0000-val_total_loss=0.4923.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_total_loss improved by 0.322 >= min_delta = 0.0001. New best score: 0.171\n",
      "Epoch 1, global step 160: 'val_total_loss' reached 0.17062 (best 0.17062), saving model to '/root/autodl-tmp/new/original8/results/reaction_model/checkpoints/best-epoch=0001-val_total_loss=0.1706.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_total_loss improved by 0.057 >= min_delta = 0.0001. New best score: 0.113\n",
      "Epoch 2, global step 240: 'val_total_loss' reached 0.11343 (best 0.11343), saving model to '/root/autodl-tmp/new/original8/results/reaction_model/checkpoints/best-epoch=0002-val_total_loss=0.1134.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 320: 'val_total_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=4` reached.\n",
      "2025-05-23 13:33:56,825 - deepreaction - INFO - Best model saved to: /root/autodl-tmp/new/original8/results/reaction_model/checkpoints/best-epoch=0002-val_total_loss=0.1134.ckpt\n",
      "2025-05-23 13:33:56,826 - deepreaction - INFO - Creating dataloader: batch_size=32, num_workers=2, eval_mode=True\n",
      "2025-05-23 13:33:56,827 - deepreaction - INFO - Running test evaluation\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca1584aa84004e249c1ddfbf8088363c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-23 13:33:59,582 - deepreaction - INFO - Test results: {'test_total_loss': 0.17179837822914124, 'Test MAE DG_act': 2.1112043857574463, 'Test RMSE DG_act': 2.7726213932037354, 'Test R2 DG_act': 0.8459211587905884, 'Test MAE DrG': 3.1726670265197754, 'Test RMSE DrG': 4.215632915496826, 'Test R2 DrG': 0.8971480131149292, 'Test Avg MAE': 2.6419358253479004, 'Test Avg RMSE': 3.494127035140991, 'Test Avg R2': 0.8715345859527588}\n",
      "2025-05-23 13:33:59,584 - deepreaction - INFO - Training completed in 147.44 seconds\n",
      "2025-05-23 13:33:59,585 - deepreaction - INFO - Training metrics saved to ./results/reaction_model/metrics.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      Test Avg MAE          2.6419358253479004\n",
      "       Test Avg R2          0.8715345859527588\n",
      "      Test Avg RMSE          3.494127035140991\n",
      "     Test MAE DG_act        2.1112043857574463\n",
      "      Test MAE DrG          3.1726670265197754\n",
      "     Test R2 DG_act         0.8459211587905884\n",
      "       Test R2 DrG          0.8971480131149292\n",
      "    Test RMSE DG_act        2.7726213932037354\n",
      "      Test RMSE DrG          4.215632915496826\n",
      "     test_total_loss        0.17179837822914124\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Get data splits\n",
    "    train_data, val_data, test_data, scalers = dataset.get_data_splits()\n",
    "\n",
    "    # Start training\n",
    "    train_metrics = trainer.fit(\n",
    "        train_dataset=train_data,\n",
    "        val_dataset=val_data,\n",
    "        test_dataset=test_data,\n",
    "        scalers=scalers,\n",
    "        checkpoint_path=config.training.checkpoint_path,\n",
    "        mode=config.training.mode\n",
    "    )\n",
    "    \n",
    "    training_success = True\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nTraining failed with error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    training_success = False\n",
    "    train_metrics = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Training Results\n",
    "\n",
    "Display training results and save locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "TRAINING COMPLETED SUCCESSFULLY\n",
      "==================================================\n",
      "Training time: 147.44 seconds\n",
      "Epochs completed: 4\n",
      "Best model saved to: /root/autodl-tmp/new/original8/results/reaction_model/checkpoints/best-epoch=0002-val_total_loss=0.1134.ckpt\n",
      "Test results: {'test_total_loss': 0.17179837822914124, 'Test MAE DG_act': 2.1112043857574463, 'Test RMSE DG_act': 2.7726213932037354, 'Test R2 DG_act': 0.8459211587905884, 'Test MAE DrG': 3.1726670265197754, 'Test RMSE DrG': 4.215632915496826, 'Test R2 DrG': 0.8971480131149292, 'Test Avg MAE': 2.6419358253479004, 'Test Avg RMSE': 3.494127035140991, 'Test Avg R2': 0.8715345859527588}\n",
      "All outputs saved in: ./results/reaction_model\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "if training_success and train_metrics is not None:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"TRAINING COMPLETED SUCCESSFULLY\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(f\"Training time: {train_metrics.get('training_time', 0):.2f} seconds\")\n",
    "    print(f\"Epochs completed: {train_metrics.get('epochs_completed', 0)}\")\n",
    "    \n",
    "    if 'best_model_path' in train_metrics and train_metrics['best_model_path']:\n",
    "        print(f\"Best model saved to: {train_metrics['best_model_path']}\")\n",
    "    elif config.training.save_last_model and 'last_model_path' in train_metrics:\n",
    "        print(f\"Last model saved to: {train_metrics['last_model_path']}\")\n",
    "    \n",
    "    if 'test_results' in train_metrics and train_metrics['test_results']:\n",
    "        print(f\"Test results: {train_metrics['test_results']}\")\n",
    "    \n",
    "    print(f\"All outputs saved in: {config.training.out_dir}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"TRAINING FAILED\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"Please check the error messages above for details.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
