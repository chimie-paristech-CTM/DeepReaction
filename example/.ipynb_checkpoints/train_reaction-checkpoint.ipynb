{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24865530",
   "metadata": {},
   "source": [
    "# Training Demo for DeepReaction\n",
    "\n",
    "This notebook demonstrates how to train a molecular reaction prediction model using the DeepReaction framework with a simplified unified configuration interface."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95da61b8",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ba6d7c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Import from deepreaction package using the new unified interface\n",
    "from deepreaction import ReactionTrainer, ReactionDataset, Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f9df28",
   "metadata": {},
   "source": [
    "## 2. Define Training Parameters\n",
    "\n",
    "All parameters are defined in a single dictionary for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "850a76e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all parameters in a single dictionary\n",
    "params = {\n",
    "    # Dataset parameters\n",
    "    'dataset': 'XTB',\n",
    "    'readout': 'mean',\n",
    "    'dataset_root': './dataset/DATASET_DA_F',  # Adjust path if needed\n",
    "    'dataset_csv': './dataset/DATASET_DA_F/dataset_xtb_final.csv', # Adjust path if needed\n",
    "    'train_ratio': 0.8,\n",
    "    'val_ratio': 0.1,\n",
    "    'test_ratio': 0.1,\n",
    "    'target_fields': ['G(TS)', 'DrG'],\n",
    "    'target_weights': [1.0, 1.0],\n",
    "    'input_features': ['G(TS)_xtb', 'DrG_xtb'],\n",
    "    'file_patterns': ['*_reactant.xyz', '*_ts.xyz', '*_product.xyz'],\n",
    "    'file_dir_pattern': 'reaction_*',\n",
    "    'id_field': 'ID',\n",
    "    'dir_field': 'R_dir',\n",
    "    'reaction_field': 'reaction',\n",
    "    'cv_folds': 0, # Set > 0 for cross-validation\n",
    "    'use_scaler': True,  # Controls whether to scale target values and pass scalers to trainer\n",
    "    \n",
    "    # Model parameters (DimeNet++ specific)\n",
    "    'model_type': 'dimenet++',\n",
    "    'node_dim': 128,\n",
    "    'dropout': 0.1,\n",
    "    'prediction_hidden_layers': 3,\n",
    "    'prediction_hidden_dim': 512,\n",
    "    'use_layer_norm': False,\n",
    "    \n",
    "    'hidden_channels': 128,\n",
    "    'num_blocks': 5,\n",
    "    'int_emb_size': 64,\n",
    "    'basis_emb_size': 8,\n",
    "    'out_emb_channels': 256,\n",
    "    'num_spherical': 7,\n",
    "    'num_radial': 6,\n",
    "    'cutoff': 5.0,\n",
    "    'envelope_exponent': 5,\n",
    "    'num_before_skip': 1,\n",
    "    'num_after_skip': 2,\n",
    "    'num_output_layers': 3,\n",
    "    'max_num_neighbors': 32,\n",
    "    \n",
    "    # Training parameters\n",
    "    'batch_size': 16,\n",
    "    'eval_batch_size': None, # Uses batch_size if None\n",
    "    'lr': 0.0005,\n",
    "    'finetune_lr': None,\n",
    "    'epochs': 3,  # Set to 10 for demonstration\n",
    "    'min_epochs': 0,\n",
    "    'early_stopping': 40,\n",
    "    'optimizer': 'adamw',\n",
    "    'scheduler': 'warmup_cosine',\n",
    "    'warmup_epochs': 10,\n",
    "    'min_lr': 1e-7,\n",
    "    'weight_decay': 0.0001,\n",
    "    'random_seed': 42234,\n",
    "    \n",
    "    'out_dir': './results/reaction_model', # Adjust path if needed\n",
    "    'save_best_model': True,\n",
    "    'save_last_model': False,\n",
    "    'checkpoint_path': None, # Path to a .ckpt file to resume/continue\n",
    "    'mode': 'continue', # 'train' or 'continue'\n",
    "    'freeze_base_model': False,\n",
    "    \n",
    "    'cuda': True, # Set to False to force CPU\n",
    "    'gpu_id': 0,\n",
    "    'num_workers': 4 # Number of workers for data loading\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4867a4d2",
   "metadata": {},
   "source": [
    "## 3. Set Up GPU and Output Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b699333f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA GeForce RTX 4090 D\n",
      "Output directory created/exists: ./results/reaction_model\n"
     ]
    }
   ],
   "source": [
    "# Setup GPU or CPU\n",
    "if params['cuda'] and torch.cuda.is_available():\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(params['gpu_id'])\n",
    "    device = torch.device(f\"cuda:{params['gpu_id']}\")\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(device)}\")\n",
    "else:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")\n",
    "    params['cuda'] = False\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(params['out_dir'], exist_ok=True)\n",
    "print(f\"Output directory created/exists: {params['out_dir']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099063b8",
   "metadata": {},
   "source": [
    "## 4. Create Configuration Object\n",
    "\n",
    "Use the unified configuration interface to create the configuration from parameters dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7ff8ef3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration created successfully\n"
     ]
    }
   ],
   "source": [
    "# Create configuration directly from parameters dictionary\n",
    "config = Config.from_params(params)\n",
    "print(\"Configuration created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f587e70",
   "metadata": {},
   "source": [
    "## 5. Load and Prepare Dataset\n",
    "\n",
    "Load the dataset with the unified configuration object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f2fee877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from unified configuration\n",
      "Error checking saved data: 'NoneType' object is not subscriptable\n",
      "Using target fields: ['G(TS)', 'DrG']\n",
      "Using input features: ['G(TS)_xtb', 'DrG_xtb']\n",
      "Using file patterns: ['*_reactant.xyz', '*_ts.xyz', '*_product.xyz']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing reactions:   0%|          | 0/1582 [00:00<?, ?it/s]\u001b[A\n",
      "Processing reactions:   9%|▊         | 135/1582 [00:00<00:01, 1348.70it/s]\u001b[A\n",
      "Processing reactions:  20%|█▉        | 315/1582 [00:00<00:00, 1611.14it/s]\u001b[A\n",
      "Processing reactions:  31%|███       | 492/1582 [00:00<00:00, 1682.44it/s]\u001b[A\n",
      "Processing reactions:  42%|████▏     | 670/1582 [00:00<00:00, 1719.28it/s]\u001b[A\n",
      "Processing reactions:  54%|█████▍    | 853/1582 [00:00<00:00, 1757.45it/s]\u001b[A\n",
      "Processing reactions:  65%|██████▌   | 1033/1582 [00:00<00:00, 1767.85it/s]\u001b[A\n",
      "Processing reactions:  76%|███████▋  | 1210/1582 [00:00<00:00, 1740.13it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Folder dataset/DATASET_DA_F/reaction_R6866 does not exist, skipping reaction_id ID79335\n",
      "Warning: Folder dataset/DATASET_DA_F/reaction_R6867 does not exist, skipping reaction_id ID79335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing reactions:  88%|████████▊ | 1385/1582 [00:00<00:00, 1730.18it/s]\u001b[A\n",
      "Processing reactions: 100%|██████████| 1582/1582 [00:00<00:00, 1715.42it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1580 reactions, skipped 2 reactions\n",
      "Saved metadata to dataset/DATASET_DA_F/processed/metadata.json\n",
      "Processed 1580 reactions, saved to dataset/DATASET_DA_F/processed/data_038b0f2fed6b.pt\n",
      "Dataset split: train 1269, validation 162, test 149 samples\n",
      "Epoch 3:  88%|████████▊ | 70/80 [24:46<03:32,  0.05it/s, v_num=15, train_total_loss_step=31.70, val_total_loss_step=12.70, val_total_loss_epoch=21.50, train_total_loss_epoch=50.80]\n",
      "Dataset loaded successfully\n",
      "Dataset stats: Train: 1269, Validation: 162, Test: 149\n"
     ]
    }
   ],
   "source": [
    "# Load dataset using the unified configuration\n",
    "print(\"Loading dataset from unified configuration\")\n",
    "\n",
    "# Pass the entire config object to the dataset\n",
    "dataset = ReactionDataset(config=config)\n",
    "\n",
    "print(\"Dataset loaded successfully\")\n",
    "data_stats = dataset.get_data_stats()\n",
    "print(f\"Dataset stats: Train: {data_stats['train_size']}, Validation: {data_stats['val_size']}, Test: {data_stats['test_size']}\")\n",
    "if config.reaction.cv_folds > 0:\n",
    "    print(f\"Cross-validation enabled with {dataset.get_num_folds()} folds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce37733f",
   "metadata": {},
   "source": [
    "## 6. Initialize and Train Model\n",
    "\n",
    "Create a trainer and train the model with the simplified interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c481d96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using scaler: True\n",
      "Trainer initialized successfully\n",
      "Starting training with 3 epochs\n"
     ]
    }
   ],
   "source": [
    "# Create trainer - use scaler based on the config parameter\n",
    "scalers = dataset.get_scalers() if config.reaction.use_scaler else None\n",
    "\n",
    "print(f\"Using scaler: {config.reaction.use_scaler}\")\n",
    "\n",
    "trainer = ReactionTrainer(\n",
    "    config=config,\n",
    "    scalers=scalers  # Pass scalers only if use_scaler is True\n",
    ")\n",
    "\n",
    "print(\"Trainer initialized successfully\")\n",
    "print(f\"Starting training with {config.training.max_epochs} epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a25f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using explicitly provided num_targets: 2\n",
      "Using provided target weights: [1.0, 1.0]\n",
      "Using target field names: ['G(TS)', 'DrG']\n",
      "Final model configuration: num_targets=2, target_field_names=['G(TS)', 'DrG'], target_weights=[1.0, 1.0]\n",
      "Initializing model with output_dim=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/root/miniconda3/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /root/DeepReaction/results/reaction_model/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type                      | Params | Mode \n",
      "---------------------------------------------------------------------\n",
      "0 | model          | MoleculePredictionModel   | 3.5 M  | train\n",
      "1 | net            | DimeNetPlusPlus           | 2.3 M  | train\n",
      "2 | readout_module | MeanReadout               | 0      | train\n",
      "3 | regr_or_cls_nn | MultiTargetPredictionHead | 1.2 M  | train\n",
      "---------------------------------------------------------------------\n",
      "3.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.5 M     Total params\n",
      "13.866    Total estimated model params size (MB)\n",
      "193       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG - MultiTargetPredictionHead initialized with 2 targets\n",
      "DEBUG - MultiTargetPredictionHead input_dim: 130\n",
      "DEBUG - Creating head for target 0\n",
      "DEBUG - Creating head for target 1\n",
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]DEBUG - MultiTargetPredictionHead output shape: torch.Size([16, 2])\n",
      "Epoch 0: 100%|██████████| 80/80 [00:35<00:00,  2.24it/s, v_num=22, train_total_loss_step=0.597]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|█████████ | 10/11 [00:03<00:00,  3.28it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 11/11 [00:03<00:00,  3.36it/s]\u001b[A\n",
      "Epoch 0: 100%|██████████| 80/80 [00:39<00:00,  2.03it/s, v_num=22, train_total_loss_step=0.597, val_total_loss_step=0.203, val_total_loss_epoch=0.432, train_total_loss_epoch=1.440]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_total_loss improved. New best score: 0.432\n",
      "Epoch 0, global step 80: 'val_total_loss' reached 0.43250 (best 0.43250), saving model to '/root/DeepReaction/results/reaction_model/checkpoints/best-epoch=0000-val_total_loss=0.4325.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  75%|███████▌  | 60/80 [00:22<00:07,  2.67it/s, v_num=22, train_total_loss_step=0.535, val_total_loss_step=0.203, val_total_loss_epoch=0.432, train_total_loss_epoch=1.440]"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "train_metrics = trainer.fit(\n",
    "    train_dataset=dataset.train_data,\n",
    "    val_dataset=dataset.val_data,\n",
    "    test_dataset=dataset.test_data,\n",
    "    checkpoint_path=config.training.resume_from_checkpoint,\n",
    "    mode=config.training.mode\n",
    ")\n",
    "\n",
    "print(\"Training completed successfully\")\n",
    "print(\"Metrics:\", train_metrics)\n",
    "if 'best_model_path' in train_metrics and train_metrics['best_model_path']:\n",
    "    print(f\"Best model saved to: {train_metrics['best_model_path']}\")\n",
    "elif config.training.save_last_model and 'last_model_path' in train_metrics and train_metrics['last_model_path']:\n",
    "    print(f\"Last model saved to: {train_metrics['last_model_path']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595f15e1-8f11-4ef0-9535-05cd6d42b59c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reaction",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
